\chapter{Resultados y discusión}
\label{cap:resultados}

En la figura~\ref{fig:MeasuresGraphics} y en la tabla~\ref{tab:measures}
se pueden observar los modelos entrenados junto a sus métricas de acierto
y \emph{F1} sobre el conjunto de test.

<<MeasuresData,results='asis'>>=
measures <- read.csv("../../Spark-workspace/StarCraft-Analytics/measures/measures.csv")
rownames(measures) <- c("Accuracy","AUC","F1")
measures <- as.data.frame(t(measures))
measures <- rbind(measures, c(0.9754953098794287,0.99235048718616,0.9754828794253172))
rownames(measures)[6] <- "KNN"
measures$Algorithm <- rownames(measures)
measures$Params <- c("numTrees = 150, maxDepth = 10","maxIter = 150, regParam = 0.3",
                     "Smoothing = 1", "numTrees = 150, maxDepth = 10",
                     "Hidden layers = (10,10)", "K = 3")
measures$AUC[measures$AUC == -1.0] <- 0.0
xtable::xtable(measures[,c(5,1,3)],
  caption = "Tabla con los algoritmos modelados y las medidas conseguidas",
  table.placement="H",
  label = "tab:measures" )
@



En general, todos excepto \emph{Naive Bayes} se comportan decentemente, pero hay
dos claros ganadores: \emph{Gradient Boosting Tree} y \emph{KNN}. Este último
ofrece una predicción muy precisa con un coste computacional bastante bajo,
aunque hay que tener en cuenta que para un sistema en tiempo real, podría ser
contraproducente usar un clasificador perezoso del tipo de \emph{KNN}, ya que
el tiempo de predicción será más alto que el de un clasificador tipo
\emph{Gradient Boosting Tree}, que no tiene más que realizar varias
comparaciones sencillas.


<<MeasuresGraphics, fig.cap = "Medidas obtenidas con los diversos modelos">>=
library(reshape2)

measures.melt <- melt(id.var = "Algorithm",measures[,-c(2,5)])
#colnames(measures) <- c("Algorithm","Measure","Value")
#(measures.melt)
ggplot(measures.melt, aes(Algorithm, value, fill = variable)) +
  geom_bar(position=position_dodge(),stat = "identity") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 0.8), axis.text.y = element_text(size = 8))
@

En las siguientes gráficas se tomará como referencia la importancia de la
variable tiempo, \emph{Frame}, ya que es fácil para cualquier persona pensar
que el tiempo de la partida es esencial para determinar su resultado.
Veremos que no es tan importante, existen variables más importantes que ésta
y no por pequeñas diferencias.

\newpage
Aquí las características más importantes según \emph{Gradient Boosting Tree}.

<<FeaturesGBT, fig.cap = "Características más relevantes según GBT">>=
features.gbt <- read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_gbt",
                          pattern = "*.csv", full.names = TRUE))

features <- features.gbt[,1]

features.gbt$color <- features.gbt$Importance > features.gbt$Importance[features.gbt$Feature == "Frame"]

ggplot(features.gbt, aes(reorder(Feature, Importance), Importance, fill = color)) +
  geom_bar(stat = "identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  labs(x = "Feature", fill = "Importance \n> \nImportance of Frame")
@

Para este modelo, son muy importantes variables del tipo ``observación''.
En este tipo de juegos siempre es muy importante para un jugador tener la
máxima información posible, tanto del mapa como del jugador contrario. Este
modelo registra bien ese dato: las variables más importantes son la información
que tiene un jugador sobre los edificios del contrario y la información que
tiene un jugador sobre los recursos restantes del mapa.

\newpage
Aquí las características más importantes según \emph{Random Forest}.

<<FeaturesRF, fig.cap = "Características más relevantes según RF">>=
features.rf <- read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_rf",
                          pattern = "*.csv", full.names = TRUE))

features.rf$color <- features.rf$Importance > features.rf$Importance[features.rf$Feature == "Frame"]

ggplot(features.rf, aes(reorder(Feature, Importance), Importance, fill = color)) +
  geom_bar(stat = "identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  labs(x = "Feature", fill = "Importance \n> \nImportance of Frame")
@

Para \emph{Random Forest} son mucho más importantes las variables
que indican la capacidad de carga de la población de cada jugador que el resto.
Tiene sentido: por un lado, más capacidad de carga es consecuencia de una mayor
cantidad de edificios, ya que todos ellos aumentan este valor. A su vez, mayor
número de edificios implica un abanico mayor de unidades posibles a crear,
aumentando así la probabilidad de crear unidades muy fuertes. Además, mayor
capacidad de carga implica poder crear no sólo mejores unidades, sino más
cantidad.

\newpage
Para el caso de \emph{Naive Bayes}, se presenta un \emph{Heatmap} con las
probabilidades condicionadas para cada atributo y para cada clase.

<<FeaturesNB, fig.cap = "Heatmap de la tabla de probabilidad condicionada de Naive Bayes">>=
features.nb <- exp(read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_nb",
                          pattern = "*.csv", full.names = TRUE)))

features.nb$Feature <- features
ggplot(melt(features.nb, id.vars = "Feature"), aes(reorder(Feature,value),variable, fill=value)) +
  geom_tile(colour = "grey50") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 0.8),
    axis.text.y = element_text(size = 8)) + xlab("") + ylab("") +
  ggtitle("Heatmap Naive Bayes")
@


En este caso, \emph{Naive Bayes} le da demasiada importancia a los valores
de recursos observados del mapa y al tiempo. Variables importantes presentes
en los demás modelos no son importantes en este, lo cual implica tener casi
la misma precisión que una moneda lanzada al aire. Esto es muy probable que
sea debido a la simpleza del modelo: una red bayesiana con otra topología
es más que probable que modele mejor el problema. Por esta razón se han
utilizado en trabajo anteriores en el ámbito, como se ha comentado
en~\ref{cap:introduccion}.

\newpage
Y por último, una comparación a lo largo del tiempo de la precisión de los
distintos clasificadores.

<<TimeComparisonAcc, fig.cap = "Comparación de los clasifiadores a lo largo del tiempo", fig.width = 10 >>=
measures.names <- list.files("../../Spark-workspace/StarCraft-Analytics/measures/", pattern = "measures_.*.csv")
measures.numbers <- sort(as.numeric(unlist(stringi::stri_extract_all_regex(measures.names, "[0-9]+"))))
measures.data <- lapply(measures.numbers, function(number) cbind(Measure = c("Accuracy", "AUC", "F1"),
                                                                 Frames = number,
                                                                 read.csv(paste0("../../Spark-workspace/StarCraft-Analytics/measures/measures_",number, ".csv")),
                                                                 read.csv(paste0("../../Spark-workspace/StarCraft-Analytics/measures/measuresKNN_",number, ".csv"))
                                                                 ))

avg.duration.frames <- mean(data.full$Duration)
frames.to.mins <- 15*60
avg.duration.mins <- avg.duration.frames / frames.to.mins

measures.full <- do.call(rbind, measures.data)

measures.melt <- reshape2::melt(measures.full, id.vars = c("Measure","Frames"), variable.name = "Classifier")

ggplot(subset(measures.melt, Measure == "Accuracy"), aes(Frames, value, col = Classifier)) +
  geom_line() +
  geom_point() +
  ylab("Accuracy") +
  scale_x_continuous(breaks = measures.numbers) +
  scale_y_continuous(breaks = seq(0.4,0.9,by=0.05))
@

Se ve claramente en la figura~\ref{fig:TimeComparisonAcc} como \emph{KNN} es
capaz de clasificar con más de un
\Sexpr{subset(measures.melt, Measure == "Accuracy"
              & Classifier == "KNN"
              & Frames == 9000)[1,"value"]*100}\% de
acierto con sólo 9000 frames de partida, que a 15 frames por segundo equivalen
a 10 minutos. Además, hemos visto que la media de la duración
de las partidas es de \Sexpr{avg.duration.frames} frames, que equivalen a
\Sexpr{avg.duration.mins} minutos
de partida. Esto significa que con un \Sexpr{9000 / avg.duration.frames * 100}\%
de la duración media
de una partida es suficiente para saber el vencedor de ésta con una alta
confianza. La consecuencia directa de esto es que se demuestra que no hace
falta jugar una partida completa para saber quién es más probable que gane.

Además, en esta gráfica se ve la gran diferencia entre \emph{KNN} y el segundo
mejor clasificador, \emph{Gradient Boosting}. Con 10 minutos de partida,
\emph{KNN} es mejor clasificador que \emph{Gradient Boosting} utilizando todo
el conocimiento de una partida.
