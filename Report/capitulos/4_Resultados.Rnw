\chapter{Resultados y discusión}
\label{cap:resultados}

En la figura~\ref{fig:MeasuresGraphics} y en la tabla~\ref{tab:measures}
se pueden observar los modelos entrenados junto a su precisión sobre los
conjuntos de test.

<<prepareMeasures>>=
library(reshape2)
measures.names <- list.files("../../Spark-workspace/StarCraft-Analytics/measures", full.names = TRUE)
measures.numbers <- sort(as.numeric(unlist(stringi::stri_extract_all_regex(measures.names, "[0-9]+"))))
measures.full.path <- "../../Spark-workspace/StarCraft-Analytics/measures/measures_full.csv"

if (! file.exists(measures.full.path)) {
  measuresKNN <- readSparkData("../../Spark-workspace/StarCraft-Analytics/measures/measuresKNN")
  measures.data <- lapply(measures.numbers, function(number) cbind(TestSet = 1:5,
                                                                   Frames = number,
                                                                   readSparkData(paste0("../../Spark-workspace/StarCraft-Analytics/measures/measures_",number)),
                                                                   KNN = measuresKNN[,paste0("X",number)]
  ))
  measures.full <- do.call(rbind, measures.data)
  write.csv(measures.full, measures.full.path, row.names = FALSE)

}
measures.full <- read.csv(measures.full.path)

max.duration <- max(data.full$Duration)
avg.duration.frames <- mean(data.full$Duration)
frames.to.mins <- 15*60
avg.duration.mins <- avg.duration.frames / frames.to.mins

measures.mean <- aggregate(measures.full[,3:8], by = list(Frames = measures.full$Frames), mean)
measures.median <- aggregate(measures.full[,3:8], by = list(Frames = measures.full$Frames), median)
measures.sd <- aggregate(measures.full[,3:8], by = list(Frames = measures.full$Frames), sd)
measures.norm <- aggregate(measures.full[,3:8], by = list(Frames = measures.full$Frames), function(v) shapiro.test(v)$p.value > 0.05)

mean.melt <- melt(measures.mean, id.vars = "Frames", variable.name = "Classifier", value.name = "Accuracy")
median.melt <- melt(measures.median, id.vars = "Frames", variable.name = "Classifier", value.name = "Accuracy")
sd.melt <- melt(measures.sd, id.vars = "Frames", variable.name = "Classifier", value.name = "SD")

normality <- all(measures.norm[,2:7] == T)
mean_or_median.sd <- merge( if (normality) mean.melt else median.melt,
                            sd.melt,
                            by = c("Frames", "Classifier"))


@

Se muestra la \Sexpr{if (normality) "media" else "mediana"} de la precisión para
los conjuntos de test junto a la desviación estándar como medida de error.
Se toma esta medida ya que los datos \Sexpr{if (! normality) "no"} están
centrados en la media.

<<MeasuresData,results='asis'>>=
results <- subset(mean_or_median.sd, Frames == max.duration)

params <- data.frame( Classifier = c("GBT","LR","NB","RF","MLP","KNN"),
                      Params = c("numTrees = 150, maxDepth = 10","maxIter = 150, regParam = 0.3",
                     "Smoothing = 1", "numTrees = 150, maxDepth = 10",
                     "Hidden layers = (10,10)", "K = 3"))
results <- merge(results, params, by = "Classifier")
xtable::xtable(results[,-2],
  caption = "Tabla con los algoritmos modelados y las medidas conseguidas",
  table.placement="H",
  label = "tab:measures",
  digits = 6 )
@


En general, todos excepto \emph{Naive Bayes} se comportan decentemente, pero hay
dos claros ganadores: \emph{Gradient Boosting Tree} y \emph{KNN}. Este último
ofrece una predicción muy precisa con un coste computacional bastante bajo,
aunque hay que tener en cuenta que para un sistema en tiempo real, podría ser
contraproducente usar un clasificador perezoso del tipo de \emph{KNN}, ya que
el tiempo de predicción será más alto que el de un clasificador tipo
\emph{Gradient Boosting Tree}, que no tiene más que realizar varias
comparaciones sencillas.


<<MeasuresGraphics, fig.cap = "Medidas obtenidas con los diversos modelos">>=

ggplot(subset(mean_or_median.sd, Frames == max.duration), aes(Classifier, Accuracy, fill = Classifier)) +
  geom_bar(stat = "identity") +
  geom_errorbar(aes(ymin=Accuracy-SD, ymax=Accuracy+SD),width=.3) +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 0.8), axis.text.y = element_text(size = 8))
@

En las siguientes gráficas se tomará como referencia la importancia de la
variable tiempo, \emph{Frame}, ya que es fácil para cualquier persona pensar
que el tiempo de la partida es esencial para determinar su resultado.
Veremos que no es tan importante, existen variables más importantes que ésta
y no por pequeñas diferencias.

\newpage
Aquí las características más importantes según \emph{Gradient Boosting Tree}.

<<FeaturesGBT, fig.cap = "Características más relevantes según GBT">>=
features.gbt <- read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_gbt",
                          pattern = "*.csv", full.names = TRUE))

features <- features.gbt[,1]

features.gbt$color <- features.gbt$Importance > features.gbt$Importance[features.gbt$Feature == "Frame"]

ggplot(features.gbt, aes(reorder(Feature, Importance), Importance, fill = color)) +
  geom_bar(stat = "identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  labs(x = "Feature", fill = "Importance \n> \nImportance of Frame")
@

Para este modelo, son muy importantes variables del tipo ``observación''.
En este tipo de juegos siempre es muy importante para un jugador tener la
máxima información posible, tanto del mapa como del jugador contrario. Este
modelo registra bien ese dato: las variables más importantes son la información
que tiene un jugador sobre los edificios del contrario y la información que
tiene un jugador sobre los recursos restantes del mapa.

\newpage
Aquí las características más importantes según \emph{Random Forest}.

<<FeaturesRF, fig.cap = "Características más relevantes según RF">>=
features.rf <- read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_rf",
                          pattern = "*.csv", full.names = TRUE))

features.rf$color <- features.rf$Importance > features.rf$Importance[features.rf$Feature == "Frame"]

ggplot(features.rf, aes(reorder(Feature, Importance), Importance, fill = color)) +
  geom_bar(stat = "identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  labs(x = "Feature", fill = "Importance \n> \nImportance of Frame")
@

Para \emph{Random Forest} son mucho más importantes las variables
que indican la capacidad de carga de la población de cada jugador que el resto.
Tiene sentido: por un lado, más capacidad de carga es consecuencia de una mayor
cantidad de edificios, ya que todos ellos aumentan este valor. A su vez, mayor
número de edificios implica un abanico mayor de unidades posibles a crear,
aumentando así la probabilidad de crear unidades muy fuertes. Además, mayor
capacidad de carga implica poder crear no sólo mejores unidades, sino más
cantidad.

\newpage
Para el caso de \emph{Naive Bayes}, se presenta un \emph{Heatmap} con las
probabilidades condicionadas para cada atributo y para cada clase.

<<FeaturesNB, fig.cap = "Heatmap de la tabla de probabilidad condicionada de Naive Bayes">>=
features.nb <- exp(read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_nb",
                          pattern = "*.csv", full.names = TRUE)))

features.nb$Feature <- features
ggplot(melt(features.nb, id.vars = "Feature"), aes(reorder(Feature,value),variable, fill=value)) +
  geom_tile(colour = "grey50") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 0.8),
    axis.text.y = element_text(size = 8)) + xlab("") + ylab("") +
  ggtitle("Heatmap Naive Bayes")
@


En este caso, \emph{Naive Bayes} le da demasiada importancia a los valores
de recursos observados del mapa y al tiempo. Variables importantes presentes
en los demás modelos no son importantes en este, lo cual implica tener casi
la misma precisión que una moneda lanzada al aire. Esto es muy probable que
sea debido a la simpleza del modelo: una red bayesiana con otra topología
es más que probable que modele mejor el problema. Por esta razón se han
utilizado en trabajo anteriores en el ámbito, como se ha comentado
en~\ref{cap:introduccion}.

\newpage
Y por último, una comparación a lo largo del tiempo de la precisión de los
distintos clasificadores.

<<TimeComparisonAcc, fig.cap = "Comparación de los clasificadores a lo largo del tiempo", fig.width = 10 >>=
ggplot(subset(mean_or_median.sd, Frames != max.duration), aes(Frames, Accuracy, col = Classifier)) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin=Accuracy-SD, ymax=Accuracy+SD)) +
  scale_x_continuous(breaks = measures.numbers) +
  scale_y_continuous(breaks = seq(0.4,0.9,by=0.05))
@

Se ve claramente en la figura~\ref{fig:TimeComparisonAcc} como \emph{KNN} es
capaz de clasificar con una precisión de $\Sexpr{subset(mean_or_median.sd, Classifier == "KNN" & Frames == 9000)[1,"Accuracy"]} \pm \Sexpr{subset(mean_or_median.sd, Classifier == "KNN" & Frames == 9000)[1,"SD"]}$ con
sólo 9000 frames de partida, que a 15 frames por segundo equivalen
a 10 minutos. Además, hemos visto que la media de la duración
de las partidas es de \Sexpr{avg.duration.frames} frames, que equivalen a
\Sexpr{avg.duration.mins} minutos
de partida. Esto significa que con un \Sexpr{9000 / avg.duration.frames * 100}\%
de la duración media
de una partida es suficiente para saber el vencedor de ésta con una alta
confianza. La consecuencia directa de esto es que se demuestra que no hace
falta jugar una partida completa para saber quién es más probable que gane.

Además, en esta gráfica se ve la gran diferencia entre \emph{KNN} y el segundo
mejor clasificador, \emph{Gradient Boosting}. Con 10 minutos de partida,
\emph{KNN} es mejor clasificador que \emph{Gradient Boosting} utilizando todo
el conocimiento de una partida.

Por último, se realiza un test de Friedman sobre los resultados con
todos los instantes de tiempo, disponibles en la tabla~\ref{tab:acc} para ver
si existe significación en alguno de ellos.

<<Friedman, results = "asis">>=
d <- as.matrix(subset(measures.full, Frames == max.duration)[,-c(1,2)])
fr <- friedman.test(d)

rownames(d) <- NULL

xtable::xtable(d,
  caption = "Tabla con las precisiones de los algoritmos en cada conjunto de test",
  table.placement = "H",
  label = "tab:acc",
  digits = 6)
@

Con un p-valor de \Sexpr{I(fr$p.value)}, podemos afirmar que hay significación.
Ya que la hay, veamos en la tabla~\ref{tab:pvalues} si entre pares también
existe significación. Nótese que se utiliza la corrección del p-valor de
\emph{Bonferroni}, para evitar errores al acumular pruebas.

<<Pairwise, results = "asis">>=
tam <- dim(d)
groups <- rep(1:tam[2], each=tam[1])

a <- pairwise.t.test(d, g = groups, paired = T)
out <- a$p.value
colnames(out) <- colnames(measures.full)[3:7]
rownames(out) <- colnames(measures.full)[4:8]
xtable::xtable(out,
  caption = "Tabla de p-valores obtenidos al comparar muestras con un t-test",
  table.placement="H",
  label = "tab:pvalues",
  digits = 6 )
@

Vistos los resultados de la tabla, podemos afirmar que para el nivel de
significación común, 0.05, hay diferencias significativas entre todos los
clasificadores excepto entre \emph{Regresión Logística} y \emph{Perceptrón
Multicapa}. En cualquier caso al ser clasificadores que no se comportan bien
con nuestro problema, no se tendrá en cuenta. Lo importante es que hay
diferencias significativas entre los clasificadores que mejor se comportan,
\emph{KNN} y \emph{Gradient Boosting Tree}.
