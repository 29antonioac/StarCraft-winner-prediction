\chapter{Resultados y discusión}
\label{cap:resultados}

En la figura~\ref{fig:MeasuresGraphics} y su tabla asociada se pueden observar
los modelos entrenados junto a sus métricas de acierto y \emph{F1}. \\

<<MeasuresData, fig.cap = "Tabla con los algoritmos modelados y las medidas conseguidas">>=
measures <- read.csv("../../Spark-workspace/StarCraft-Analytics/measures.csv")
rownames(measures) <- c("Accuracy","AUC","F1")
measures <- as.data.frame(t(measures))
measures$Algorithm <- rownames(measures)
measures$Params <- c("numTrees = 150, maxDepth = 10","maxIter = 150, regParam = 0.3",
                     "Smoothing = 1", "numTrees = 150, maxDepth = 10",
                     "Hidden layers = (10,10)")
measures$AUC[measures$AUC == -1.0] <- 0.0
knitr::kable(measures[,c(5,1,3)])
@
\hfill \break


En general, todos excepto \emph{Naive Bayes} se comportan decentemente, pero hay
dos claros ganadores: \emph{Gradient Boosting Tree} y \emph{KNN}. Este último
ofrece una predicción muy precisa con un coste computacional bastante bajo,
aunque hay que tener en cuenta que para un sistema en tiempo real, podría ser
contraproducente usar un clasificador perezoso del tipo de \emph{KNN}, ya que
el tiempo de predicción será más alto que el de un clasificador tipo
\emph{Gradient Boosting Tree}, que no tiene más que realizar varias
comparaciones sencillas.


<<MeasuresGraphics, fig.cap = "Medidas obtenidas con los diversos modelos">>=
library(reshape2)

measures.melt <- melt(id.var = "Algorithm",measures[,-c(2,5)])
#colnames(measures) <- c("Algorithm","Measure","Value")
#(measures.melt)
ggplot(measures.melt, aes(Algorithm, value, fill = variable)) +
  geom_bar(position=position_dodge(),stat = "identity") +
  scale_y_continuous(breaks = seq(0, 1, by = 0.1)) +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 0.8), axis.text.y = element_text(size = 8))
@

En las siguientes gráficas se tomará como referencia la importancia de la
variable tiempo, \emph{Frame}, ya que es fácil para cualquier persona pensar
que el tiempo de la partida es determinante para determinar su resultado.
Veremos que no es tan importante, existen variables más importantes que ésta
y no por pequeñas diferencias.

\newpage
Aquí las características más importantes según \emph{Gradient Boosting Tree}.

<<FeaturesGBT, fig.cap = "Características más relevantes según GBT">>=
features.gbt <- read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_gbt",
                          pattern = "*.csv", full.names = TRUE))

features <- features.gbt[,1]

features.gbt$color <- features.gbt$Importance > features.gbt$Importance[features.gbt$Feature == "Frame"]

ggplot(features.gbt, aes(reorder(Feature, Importance), Importance, fill = color)) +
  geom_bar(stat = "identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  labs(x = "Feature", fill = "Importance \n> \nImportance of Frame")
@

Para este modelo, son muy importantes variables del tipo ``observación''.
En este tipo de juegos siempre es muy importante para un jugador tener la
máxima información posible, tanto del mapa como del jugador contrario. Este
modelo registra bien ese dato: las variables más importantes son la información
que tiene un jugador sobre los edificios del contrario y la información que
tiene un jugador sobre los recursos restantes del mapa.

\newpage
Aquí las características más importantes según \emph{Random Forest}.

<<FeaturesRF, fig.cap = "Características más relevantes según RF">>=
features.rf <- read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_rf",
                          pattern = "*.csv", full.names = TRUE))

features.rf$color <- features.rf$Importance > features.rf$Importance[features.rf$Feature == "Frame"]

ggplot(features.rf, aes(reorder(Feature, Importance), Importance, fill = color)) +
  geom_bar(stat = "identity", position = position_stack(reverse = TRUE)) +
  coord_flip() +
  labs(x = "Feature", fill = "Importance \n> \nImportance of Frame")
@

Para \emph{Random Forest} son mucho más importantes que las demás las variables
que indican la capacidad de carga de la población de cada jugador. Tiene
sentido: por un lado, más capacidad de carga es consecuencia de una mayor
cantidad de edificios, ya que todos ellos aumentan este valor. A su vez, mayor
número de edificios implica un abanico mayor de unidades posibles a crear,
aumentando así la probabilidad de crear unidades muy fuertes. Además, mayor
capacidad de carga implica poder crear no sólo mejores unidades, sino más
cantidad.

\newpage
Para el caso de \emph{Naive Bayes}, se presenta un \emph{Heatmap} con las
probabilidades condicionadas para cada atributo y para cada clase.

<<FeaturesNB, fig.cap = "Heatmap de la tabla de probabilidad condicionada de Naive Bayes">>=
features.nb <- exp(read.csv(list.files("../../Spark-workspace/StarCraft-Analytics/features_nb",
                          pattern = "*.csv", full.names = TRUE)))

features.nb$Feature <- features
ggplot(melt(features.nb, id.vars = "Feature"), aes(reorder(Feature,value),variable, fill=value)) +
  geom_tile(colour = "grey50") +
  theme(axis.text.x = element_text(angle = 45, vjust = 0.8, hjust = 0.8),
    axis.text.y = element_text(size = 8)) + xlab("") + ylab("") +
  ggtitle("Heatmap Naive Bayes")
@


En este caso, \emph{Naive Bayes} le da demasiada importancia a los valores
de recursos observados del mapa y al tiempo. Variables importantes presentes
en los demás modelos no son importantes en este, lo cual implica tener casi
la misma precisión que una moneda lanzada al aire. Esto es muy probable que
sea debido a la simpleza del modelo: una red bayesiana con otra topología
es más que probable que modele mejor el problema. Por esta razón se han
utilizado en trabajo anteriores en el ámbito, como se ha comentado
en~\ref{cap:introduccion}.
